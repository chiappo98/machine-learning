{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 2","language":"python","name":"python2"},"language_info":{"codemirror_mode":{"name":"ipython","version":2},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython2","version":"2.7.13"},"colab":{"provenance":[],"collapsed_sections":["6NyHWASMpbyq","_hXMsaB0wVxk","F0-YQZkAwVyW","0jDFgpsWwVye","u6gwM2Z4wVyk","gmbTN4qiwVyo","L86TrKElwVyp","AvXL00WCwVyp"]}},"cells":[{"cell_type":"markdown","metadata":{"id":"DAcD2u6uwVxh"},"source":["# Evaluate the performance of ML algos with Resampling"]},{"cell_type":"markdown","metadata":{"id":"txViSnbzY6TR"},"source":["We are going to look at 4 different techniques that we can use to split up our training dataset and create useful estimates of performance for our ML algorithms:\n","\n","1. Split into Train and Test Sets\n","1. k-fold Cross-Validation\n","1. Leave One Out Cross-Validation\n","1. Repeated Random Test-Train Splits"]},{"cell_type":"markdown","metadata":{"id":"6NyHWASMpbyq"},"source":["## 0. Import the data"]},{"cell_type":"code","metadata":{"id":"egGmPYr6pblR"},"source":["import pandas as pd\n","\n","url = 'https://raw.githubusercontent.com/dbonacorsi/AMLBas2122/main/datasets/pima-indians-diabetes.data.csv'\n","\n","names = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']\n","data = pd.read_csv(url, names=names)\n","data"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"_hXMsaB0wVxk"},"source":["## 1. Split into Train and Test Sets"]},{"cell_type":"markdown","metadata":{"id":"_8RaMNPVccVP"},"source":["The simplest method that we can use to evaluate the performance of a ML algorithm is to separate the dataset, and use (at least) different training and testing datasets (e.g. 2/3 and 1/3, but choices may vary).\n","\n","This algorithm evaluation technique is very fast, and has pros and cons:\n","* _Pro_. Ideal for large datasets. Fast (so use it for algos slow in training)\n","* _Con_. High variance.\n","\n","\n","\n"]},{"cell_type":"code","metadata":{"id":"2Qu_ml5owVxl"},"source":["from sklearn.model_selection import train_test_split\n","from sklearn.linear_model import LogisticRegression"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"scrolled":true,"id":"yzT3ldEtwVxo"},"source":["array = data.values\n","X = array[:,0:8]\n","Y = array[:,8]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"BVBhj9VXwVxr"},"source":["test_size = 0.33\n","seed = 7"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["NOTE: importance of the random seed."],"metadata":{"id":"1iGGGbxU34s7"}},{"cell_type":"code","metadata":{"id":"OQ2GUpzjwVxu"},"source":["%%time\n","# Evaluate using a train and a test set\n","X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=test_size, random_state=seed)\n","#model = LogisticRegression()   \n","model = LogisticRegression(solver='lbfgs', max_iter=500)         \n","model.fit(X_train, Y_train)             \n","result = model.score(X_test, Y_test)    \n","print(\"Accuracy: %.3f%%\" % (result*100.0))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Q9OaA7TQfw7I"},"source":["---"]},{"cell_type":"markdown","metadata":{"id":"HMPTbXT1wVxx"},"source":["### <font color='red'>Exercise 1</font>"]},{"cell_type":"markdown","metadata":{"id":"lBLCtCkawVxx"},"source":["Try to change the seed, and re-train. Does accuracy change? Is it reproducible for a a fixed seed? for different seeds, could you measure its variance? (up to your curiosity here, but no need to do more here than just few tries and get a feeling.. but you can do more and clever tests..)"]},{"cell_type":"code","metadata":{"id":"m2qqRJk-xhJH"},"source":["# type your code below"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"XTOf-eg8fx-i"},"source":["---"]},{"cell_type":"markdown","metadata":{"id":"k59kKKq_wVyA"},"source":["### <font color='red'>Exercise 2</font>"]},{"cell_type":"markdown","metadata":{"id":"kflKRgO0wVyA"},"source":["What happens if I check accuracy on the _train_ set (conceptually wrong)? Do I see something different or not? What is the drawback if I do this mistake?"]},{"cell_type":"code","metadata":{"id":"nUH8RXqB09R_"},"source":["# type your code below"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"WS-tPxm9fzHJ"},"source":["---"]},{"cell_type":"markdown","metadata":{"id":"zNCxbHA1wVyP"},"source":["### <font color='red'>Exercise 3</font>"]},{"cell_type":"markdown","metadata":{"id":"EaSn-xI3wVyP"},"source":["What if change the training/test ratio?"]},{"cell_type":"code","metadata":{"id":"6mnkaabe0-kQ"},"source":["# type your code below"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"81jkbtANgE1Y"},"source":["---"]},{"cell_type":"markdown","metadata":{"id":"F0-YQZkAwVyW"},"source":["## 2. K-fold Cross-Validation"]},{"cell_type":"markdown","metadata":{"id":"6L7CDFjkzQYn"},"source":["It works by **splitting the dataset into k-parts** (e.g. $k=5$ or $k=10$). Each split of the data is called a $fold$. The algorithm is trained on $k-1$ folds (with 1 held back), and then tested on the held-back fold. This is also repeated, so that _each_ fold of the dataset is given a chance to be the held-back test set. So you repeat it k times. After running cross-validation you end up with $k$ different performance scores that you can summarize using a mean and a standard deviation. \n"]},{"cell_type":"markdown","metadata":{"id":"RdXgfR4PirTJ"},"source":["**The choice of $k$ is a trade-off** between reasonably large size of each test partition, and a number that allows enough repetitions of the train-test evaluation of the algorithm.\n","\n","**$k$ values of $3$, $5$ and $10$ are common** (at least for modest-size datasets in the thousands or tens of thousands of records). In the example below we use 10-fold cross-validation."]},{"cell_type":"code","metadata":{"id":"Y9tS9Sb0wVyW"},"source":["from sklearn.model_selection import KFold\n","from sklearn.model_selection import cross_val_score   # <---\n","from sklearn.linear_model import LogisticRegression"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"hLE_nHF5wVyZ"},"source":["# Evaluate using Cross Validation\n","num_folds = 5\n","seed = 7\n","\n","kfold = KFold(n_splits=num_folds, random_state=seed, shuffle=True)\n","#model = LogisticRegression()\n","model = LogisticRegression(solver='lbfgs', max_iter=500)\n","results = cross_val_score(model, X, Y, cv=kfold)\n","print(\"Accuracy: %.3f%% (%.3f%%)\" % (results.mean()*100.0, results.std()*100.0))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"3_tYK3AWwVyb"},"source":["You can see that we report both the mean and the standard deviation of the performance measure.\n"]},{"cell_type":"markdown","metadata":{"id":"yN1DWy2FkWH_"},"source":["---"]},{"cell_type":"markdown","metadata":{"id":"WXGOB_6qwVyb"},"source":["### <font color='red'>Exercise 4</font>"]},{"cell_type":"markdown","metadata":{"id":"RbpMa5EKwVyc"},"source":["<div class=\"alert alert-block alert-info\">\n","What if I change the nb folds?\n","</div>"]},{"cell_type":"code","metadata":{"id":"2O1NeZfW0_ui"},"source":["# type your code below"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"0jDFgpsWwVye"},"source":["## 3. Leave One Out Cross-Validation"]},{"cell_type":"markdown","metadata":{"id":"TsI_mVLWwVyf"},"source":["You can configure cross-validation so that the size of the fold is 1 ($k=n$, i.e. $k$ is set to the number of observations in your dataset). "]},{"cell_type":"code","metadata":{"id":"80lH8gNLwVyf"},"source":["from sklearn.model_selection import LeaveOneOut       # <---\n","from sklearn.model_selection import cross_val_score\n","from sklearn.linear_model import LogisticRegression"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"B92zPwKwwVyh"},"source":["# Evaluate using Leave One Out Cross Validation\n","loocv = LeaveOneOut()\n","#model = LogisticRegression()\n","model = LogisticRegression(solver='lbfgs', max_iter=500)\n","results = cross_val_score(model, X, Y, cv=loocv)\n","print(\"Accuracy: %.3f%% (%.3f%%)\" % (results.mean()*100.0, results.std()*100.0))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"x4gRjJOvwVyj"},"source":["(*NOTE: probably not so visible in this small example, but the time it took to run this is larger than the previous one..*)\n","\n","You can see in the standard deviation that the score has **higher variance** than the k-fold cross-validation results described above."]},{"cell_type":"markdown","metadata":{"id":"u6gwM2Z4wVyk"},"source":["## 4. Repeated Random Test-Train Splits"]},{"cell_type":"markdown","metadata":{"id":"ku79ofdQz-0B"},"source":["Another variation on k-fold cross-validation is to **create a random split of the data** like the train/test split described above, but **repeat multiple times the process of splitting and evaluation of the algorithm**, like cross-validation.\n","\n","The example below splits the data into a 67%/33% train/test split and repeats the process 10 times."]},{"cell_type":"code","metadata":{"id":"ZKBoxgB3wVyk"},"source":["from sklearn.model_selection import ShuffleSplit      # <---\n","from sklearn.model_selection import cross_val_score\n","from sklearn.linear_model import LogisticRegression"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"iKVeSQ3SwVym"},"source":["# Evaluate using Shuffle Split Cross Validation\n","n_splits = 100\n","test_size = 0.33\n","seed = 7\n","\n","kfold = ShuffleSplit(n_splits=n_splits, test_size=test_size, random_state=seed)\n","#model = LogisticRegression()\n","model = LogisticRegression(solver='lbfgs', max_iter=500)\n","results = cross_val_score(model, X, Y, cv=kfold)\n","print(\"Accuracy: %.3f%% (%.3f%%)\" % (results.mean()*100.0, results.std()*100.0))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"tni5i-f_wVyo"},"source":["We can see that in this case the distribution of the performance measure is on par with\n","k-fold cross-validation above."]},{"cell_type":"markdown","metadata":{"id":"gmbTN4qiwVyo"},"source":["## OK, fine, but.. what techniques to use when?!?"]},{"cell_type":"markdown","metadata":{"id":"s0ePQcYT0IZX"},"source":["Discussion at the lecture."]},{"cell_type":"markdown","metadata":{"id":"L86TrKElwVyp"},"source":["## Summary"]},{"cell_type":"markdown","metadata":{"id":"9Wmx7bsxwVyp"},"source":["What we did:\n","\n","* we discovered 4 statistical techniques that we can use to estimate the performance of ML algorithms, called Resampling. "]},{"cell_type":"markdown","metadata":{"id":"AvXL00WCwVyp"},"source":["## What's next "]},{"cell_type":"markdown","metadata":{"id":"KaIOetr1wVyq"},"source":["Now we will see how you can evaluate the performance of classification and regression algorithms using a suite of different metrics and built in evaluation reports."]}]}